{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\cvproject\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from torch import functional as F\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchinfo import torchinfo\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import albumentations as A\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torchmetrics\n",
    "from torchvision.utils import save_image, make_grid\n",
    "import cv2\n",
    "import os, glob\n",
    "\n",
    "import efficientunet\n",
    "import random\n",
    "\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'Datasets/Mask detection/Face Mask Dataset/'\n",
    "train_dir = dataset_path+'Train/'\n",
    "val_dir = dataset_path+'Validation/'\n",
    "test_dir = dataset_path+'Test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = (256, 256)            # before (64, 64)\n",
    "\n",
    "rescale_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize(sizes, antialias= False)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.hstack([torch.ones(5), torch.zeros(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(path):\n",
    "    mask_files = glob.glob(path + 'WithMask/' +'*.png')\n",
    "    nomask_files = glob.glob(path + 'WithoutMask/' +'*.png')\n",
    "\n",
    "    mask_images = [rescale_transform(Image.open(x)) for x in tqdm(mask_files)]\n",
    "    unmasked_images = [rescale_transform(Image.open(x)) for x in tqdm(nomask_files)]\n",
    "\n",
    "    mask_labels = torch.ones(len(mask_images))\n",
    "    unmask_labels = torch.zeros(len(unmasked_images))\n",
    "\n",
    "    mask_images = torch.stack(mask_images)\n",
    "    unmasked_images = torch.stack(unmasked_images)\n",
    "    images = torch.vstack([mask_images, unmasked_images])\n",
    "    labels = torch.hstack([mask_labels, unmask_labels])\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:11<00:00, 442.10it/s]\n",
      "100%|██████████| 5000/5000 [00:06<00:00, 828.29it/s]\n"
     ]
    }
   ],
   "source": [
    "train_images, train_labels = get_files(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:00<00:00, 440.82it/s]\n",
      "100%|██████████| 400/400 [00:00<00:00, 820.37it/s]\n"
     ]
    }
   ],
   "source": [
    "val_images, val_labels = get_files(val_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalisation = transforms.Normalize(0.5, 0.5)\n",
    "\n",
    "augmentation = transforms.RandomAffine(\n",
    "    30, (0.15, 0.15), (0.8, 1.2), 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskDataset(Dataset):\n",
    "    def __init__(self, images, labels, augmentation = None):\n",
    "        self.images = images\n",
    "        self.augmentation = augmentation\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = normalisation(self.images[idx])\n",
    "        if(self.augmentation is not None):\n",
    "            img = self.augmentation(img)\n",
    "        return img, self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MaskDataset(train_images, train_labels, augmentation = augmentation)\n",
    "val_dataset = MaskDataset(val_images, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 250\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, BATCH_SIZE, shuffle = True)\n",
    "val_dataloader   = DataLoader(val_dataset, BATCH_SIZE, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 5, 3)        # out = 254\n",
    "        self.conv2 = nn.Conv2d(5, 10, 3)       # in = 127, out = 125\n",
    "        self.conv3 = nn.Conv2d(10, 15, 5)       # in = 63, out = 61\n",
    "        self.conv4 = nn.Conv2d(15, 20, 7)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(3)\n",
    "\n",
    "        # self.fc1 = nn.Linear(135, 64)\n",
    "        self.o_n = nn.Linear(735, 1)\n",
    "\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, inpt):\n",
    "        out = self.activation(self.conv1(inpt))\n",
    "        out = self.pool(out)\n",
    "        \n",
    "        out = self.activation(self.conv2(out))\n",
    "        out = self.pool(out)\n",
    "\n",
    "        out = self.activation(self.conv3(out))\n",
    "        out = self.pool(out)\n",
    "\n",
    "        out = self.flatten(out)\n",
    "\n",
    "        # print(out.shape)\n",
    "        \n",
    "\n",
    "        # out = self.activation(self.fc1(out))\n",
    "        out = self.o_n(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "\n",
    "    def __init__(self, patience=5, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "        \n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0812]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN().forward(torch.randn(1, 3, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CNN                                      [5, 1]                    14,720\n",
       "├─Conv2d: 1-1                            [5, 5, 254, 254]          140\n",
       "├─ReLU: 1-2                              [5, 5, 254, 254]          --\n",
       "├─MaxPool2d: 1-3                         [5, 5, 84, 84]            --\n",
       "├─Conv2d: 1-4                            [5, 10, 82, 82]           460\n",
       "├─ReLU: 1-5                              [5, 10, 82, 82]           --\n",
       "├─MaxPool2d: 1-6                         [5, 10, 27, 27]           --\n",
       "├─Conv2d: 1-7                            [5, 15, 23, 23]           3,765\n",
       "├─ReLU: 1-8                              [5, 15, 23, 23]           --\n",
       "├─MaxPool2d: 1-9                         [5, 15, 7, 7]             --\n",
       "├─Flatten: 1-10                          [5, 735]                  --\n",
       "├─Linear: 1-11                           [5, 1]                    736\n",
       "==========================================================================================\n",
       "Total params: 19,821\n",
       "Trainable params: 19,821\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 70.59\n",
       "==========================================================================================\n",
       "Input size (MB): 3.93\n",
       "Forward/backward pass size (MB): 15.91\n",
       "Params size (MB): 0.02\n",
       "Estimated Total Size (MB): 19.86\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchinfo.summary(CNN(), (5, 3, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3452, accuracy = 0.8599: 100%|██████████| 40/40 [01:06<00:00,  1.65s/it]\n",
      "Validation loss: 0.1588, accuracy = 0.9525: 100%|██████████| 4/4 [00:00<00:00,  8.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Train Loss: 0.3452, Train Accuracy: 0.8599\n",
      "Epoch [1/25], Val Loss: 0.1588, Val Accuracy: 0.9525\n",
      "Validation loss decreased (inf --> 0.158771).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1822, accuracy = 0.9320: 100%|██████████| 40/40 [01:06<00:00,  1.67s/it]\n",
      "Validation loss: 0.1090, accuracy = 0.9613: 100%|██████████| 4/4 [00:00<00:00,  8.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/25], Train Loss: 0.1822, Train Accuracy: 0.9320\n",
      "Epoch [2/25], Val Loss: 0.1090, Val Accuracy: 0.9613\n",
      "Validation loss decreased (0.158771 --> 0.108976).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1579, accuracy = 0.9424: 100%|██████████| 40/40 [01:07<00:00,  1.68s/it]\n",
      "Validation loss: 0.0937, accuracy = 0.9712: 100%|██████████| 4/4 [00:00<00:00,  9.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/25], Train Loss: 0.1579, Train Accuracy: 0.9424\n",
      "Epoch [3/25], Val Loss: 0.0937, Val Accuracy: 0.9712\n",
      "Validation loss decreased (0.108976 --> 0.093704).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1377, accuracy = 0.9503: 100%|██████████| 40/40 [01:06<00:00,  1.67s/it]\n",
      "Validation loss: 0.0848, accuracy = 0.9712: 100%|██████████| 4/4 [00:00<00:00, 10.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/25], Train Loss: 0.1377, Train Accuracy: 0.9503\n",
      "Epoch [4/25], Val Loss: 0.0848, Val Accuracy: 0.9712\n",
      "Validation loss decreased (0.093704 --> 0.084787).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1409, accuracy = 0.9492: 100%|██████████| 40/40 [01:06<00:00,  1.66s/it]\n",
      "Validation loss: 0.1045, accuracy = 0.9650: 100%|██████████| 4/4 [00:00<00:00,  9.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/25], Train Loss: 0.1409, Train Accuracy: 0.9492\n",
      "Epoch [5/25], Val Loss: 0.1045, Val Accuracy: 0.9650\n",
      "EarlyStopping counter: 1 out of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1458, accuracy = 0.9474: 100%|██████████| 40/40 [01:07<00:00,  1.68s/it]\n",
      "Validation loss: 0.0967, accuracy = 0.9750: 100%|██████████| 4/4 [00:00<00:00, 10.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/25], Train Loss: 0.1458, Train Accuracy: 0.9474\n",
      "Epoch [6/25], Val Loss: 0.0967, Val Accuracy: 0.9750\n",
      "EarlyStopping counter: 2 out of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1364, accuracy = 0.9527: 100%|██████████| 40/40 [01:06<00:00,  1.67s/it]\n",
      "Validation loss: 0.0853, accuracy = 0.9750: 100%|██████████| 4/4 [00:00<00:00,  9.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/25], Train Loss: 0.1364, Train Accuracy: 0.9527\n",
      "Epoch [7/25], Val Loss: 0.0853, Val Accuracy: 0.9750\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "The Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "EPOCHS = 25\n",
    "\n",
    "train_acc = torchmetrics.classification.BinaryAccuracy().to(device)\n",
    "val_acc = torchmetrics.classification.BinaryAccuracy().to(device)\n",
    "\n",
    "model = CNN().to(device)\n",
    "optim = torch.optim.Adam(model.parameters(), lr = 3e-3)\n",
    "criterion = torch.nn.BCELoss()\n",
    "early_stopping = EarlyStopping(patience=3, verbose=True, path = 'mask_model.pth')\n",
    "\n",
    "\n",
    "for epoch_num in range(EPOCHS):\n",
    "    train_loss = 0\n",
    "    i = 0\n",
    "\n",
    "    bar = tqdm(train_dataloader)\n",
    "    for img, label in bar:\n",
    "        i+=1\n",
    "        optim.zero_grad()\n",
    "\n",
    "        img = img.to(device)\n",
    "        label = label.to(device).unsqueeze(1)\n",
    "        predictions = F.sigmoid(model(img))\n",
    "\n",
    "        batch_loss = criterion(predictions, label)\n",
    "\n",
    "        train_acc(predictions, label)\n",
    "        batch_loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        train_loss+= batch_loss.item()\n",
    "        bar.set_description_str(\"Training loss: {:.4f}, accuracy = {:.4f}\".format(train_loss/i, train_acc.compute()))\n",
    "\n",
    "    train_loss/=i\n",
    "\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        i = 0\n",
    "        bar = tqdm(val_dataloader)\n",
    "        for img, label in bar:\n",
    "            i+=1\n",
    "            optim.zero_grad()\n",
    "\n",
    "            img = img.to(device)\n",
    "            label = label.to(device).unsqueeze(1)\n",
    "            predictions = F.sigmoid(model(img))\n",
    "\n",
    "            batch_loss = criterion(predictions, label)\n",
    "\n",
    "            \n",
    "            val_acc(predictions, label)\n",
    "            val_loss+= batch_loss.item()\n",
    "            bar.set_description_str(\"Validation loss: {:.4f}, accuracy = {:.4f}\".format(val_loss/i, val_acc.compute()))\n",
    "\n",
    "        val_loss/=i\n",
    "\n",
    "\n",
    "    print(\"Epoch [{}/{}], Train Loss: {:.4f}, Train Accuracy: {:.4f}\".format(epoch_num+1, EPOCHS, train_loss, train_acc.compute()))\n",
    "    print(\"Epoch [{}/{}], Val Loss: {:.4f}, Val Accuracy: {:.4f}\".format(epoch_num+1, EPOCHS, val_loss, val_acc.compute()))\n",
    "    early_stopping(val_loss, model)\n",
    "\n",
    "    train_acc.reset()\n",
    "    val_acc.reset()\n",
    "\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        print('-'*60)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('cvproject')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8e9b273093b79eabda493c170a15e7ff42f4736405ada6f2b68f061601f943a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
